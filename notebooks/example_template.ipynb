{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import zipfile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(\"..\")  # Go up one level to reach the project root\n",
    "sys.path.append(project_root)\n",
    "from src.cleaning.pre_processing_class import PreProcessing\n",
    "from src.analysis.visualisation_class import Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "api.dataset_download_file(\n",
    "    \"snap/amazon-fine-food-reviews\",\n",
    "    file_name=\"Reviews.csv\",\n",
    "    path=config[\"data_raw_folder\"],\n",
    ")\n",
    "\n",
    "\n",
    "stem_path = config[\"data_raw_folder\"] + \"Reviews.csv.zip\"\n",
    "with zipfile.ZipFile(stem_path, \"r\") as zipref:\n",
    "    zipref.extractall(config[\"data_raw_folder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_path = config[\"data_raw_folder\"] + \"Reviews.csv\"\n",
    "df = pd.read_csv(filepath_or_buffer=stem_path, encoding=\"latin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PreProcessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 2 minutes\n",
    "p.get_dataframe_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes trailing and leading white space, also lowercases\n",
    "p.clean_column_names()\n",
    "\n",
    "# removes any duplicates and returns number of duplicates dropped\n",
    "p.remove_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercases and removes trailing/leading white space in user defined columns\n",
    "p.lowercase_strip_rows(\n",
    "    columns_to_clean=[\n",
    "        \"text\",\n",
    "        \"summary\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# This method can either fill in missing values or remove them all together either by row or column\n",
    "p.fill_or_remove_missing_values(\n",
    "    replacement_dict={\"profilename\": \"missing\", \"summary\": \"missing\"}\n",
    ")\n",
    "\n",
    "# This method can convert the entire columns datatype to a string, boolean, integer, category or float\n",
    "p.convert_datatype(column_types={})  # {'app_version_code': \"integer\"})\n",
    "\n",
    "# This method can convert a column to datetime datatype\n",
    "p.convert_to_datetime(replacement_dict={\"time\": \"s\"})\n",
    "\n",
    "# This method can take a datetime column extract specific date information and creates a new column with the new specific date info. The new column wont be in datetime format\n",
    "final_df = p.extract_date_info(\n",
    "    date_column=[\"time\"],\n",
    "    replacement_dict={\n",
    "        \"date\": True,\n",
    "        \"strftime\": True,\n",
    "        \"day_name\": True,\n",
    "        \"custom\": \"%Y-%m\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary \"Good/Bad\" rating\n",
    "def bin_rating(x):\n",
    "    if x > 3:\n",
    "        return \"Good\"\n",
    "    elif x == 3:\n",
    "        return \"Mid\"\n",
    "    elif x < 3:\n",
    "        return \"Bad\"\n",
    "    else:\n",
    "        return \"Missing\"\n",
    "\n",
    "\n",
    "final_df[\"binary_rating\"] = final_df[\"score\"].apply(bin_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"helpfullness_%\"] = (\n",
    "    final_df[\"helpfulnessnumerator\"] / final_df[\"helpfulnessdenominator\"]\n",
    ") * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualisation(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.describe_columns() #this causes issues :( maybe cause the dataset is so big>?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.plot_count_and_proportion(\n",
    "    columns=[\"score\", \"helpfulnessnumerator\", \"helpfulnessdenominator\"], dropna=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = final_df.groupby([\"time\"])[\"score\"].count().reset_index()\n",
    "\n",
    "v.custom_graph(\n",
    "    grouped_df,\n",
    "    x_column=\"time\",\n",
    "    y_column_and_type={\"score\": \"line\"},\n",
    "    xaxis_type=\"date\",\n",
    "    barmode=None,\n",
    "    z_column=None,\n",
    "    graph_title=\"count of scores over time\",\n",
    "    x_axes_title=\"time (days)\",\n",
    "    y_axes_title=\"count of scores\",\n",
    "    yaxis_range=None,\n",
    "    xaxis_range=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    final_df.groupby([\"time\", \"score\"])\n",
    "    .agg({\"score\": \"count\"})\n",
    "    .rename(columns={\"score\": \"count of score\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "v.custom_graph(\n",
    "    df=grouped_df,\n",
    "    x_column=\"time\",\n",
    "    y_column_and_type={\"count of score\": \"line\"},\n",
    "    xaxis_type=\"date\",\n",
    "    barmode=None,\n",
    "    z_column=\"score\",\n",
    "    graph_title=\"count of scores over time\",\n",
    "    x_axes_title=\"time (days)\",\n",
    "    y_axes_title=\"avg of scores\",\n",
    "    yaxis_range=None,\n",
    "    xaxis_range=[\"2008-01-01\", \"2010-01-01\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    final_df.groupby(\"time\")[\"score\"]\n",
    "    .agg([\"count\", lambda x: (x == 5).sum()])\n",
    "    .reset_index()\n",
    ")\n",
    "grouped.columns = [\"date\", \"total_count\", \"count_5\"]\n",
    "grouped[\"percentage_5\"] = (grouped[\"count_5\"] / grouped[\"total_count\"]) * 100\n",
    "\n",
    "\n",
    "v.custom_graph(\n",
    "    df=grouped,\n",
    "    x_column=\"date\",\n",
    "    y_column_and_type={\"total_count\": \"bar\", \"percentage_5\": \"line\"},\n",
    "    xaxis_type=\"date\",\n",
    "    barmode=None,\n",
    "    z_column=None,\n",
    "    graph_title=\"put in graph title\",\n",
    "    x_axes_title=\"time (days)\",\n",
    "    y_axes_title=None,\n",
    "    yaxis_range=None,\n",
    "    xaxis_range=[\"2008-01-01\", \"2009-01-01\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z column none but different lines\n",
    "grouped = (\n",
    "    final_df.groupby([\"time\", \"binary_rating\"])\n",
    "    .agg({\"binary_rating\": \"count\"})\n",
    "    .rename(columns={\"binary_rating\": \"binary_rating_count\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "v.custom_graph(\n",
    "    df=grouped,\n",
    "    x_column=\"time\",\n",
    "    y_column_and_type={\"binary_rating_count\": \"line\"},\n",
    "    xaxis_type=\"date\",\n",
    "    barmode=None,\n",
    "    z_column=\"binary_rating\",\n",
    "    graph_title=\"put in graph title\",\n",
    "    x_axes_title=\"time (days)\",\n",
    "    y_axes_title=None,\n",
    "    yaxis_range=None,\n",
    "    xaxis_range=[\"2008-01-01\", \"2009-01-01\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    final_df.groupby([\"time_day_name\", \"binary_rating\"])\n",
    "    .agg({\"binary_rating\": \"count\"})\n",
    "    .rename(columns={\"binary_rating\": \"binary_rating_count\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "v.custom_graph(\n",
    "    df=grouped,\n",
    "    x_column=\"time_day_name\",\n",
    "    y_column_and_type={\"binary_rating_count\": \"bar\"},\n",
    "    xaxis_type=\"category\",\n",
    "    barmode=\"group\",\n",
    "    z_column=\"binary_rating\",\n",
    "    graph_title=\"This is the graph title\",\n",
    "    x_axes_title=\"time (days)\",\n",
    "    y_axes_title=None,\n",
    "    yaxis_range=None,\n",
    "    xaxis_range=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.fill_or_remove_missing_values(replacement_dict={\"summary\": \"remove_row\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_good = Visualisation(df=final_df.loc[final_df[\"binary_rating\"] == \"Good\"])\n",
    "v_bad = Visualisation(df=final_df.loc[final_df[\"binary_rating\"] == \"Bad\"])\n",
    "v_mid = Visualisation(df=final_df.loc[final_df[\"binary_rating\"] == \"Mid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_bad.create_wordcloud(text=\"summary\", remove_words=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_mid.create_wordcloud(text=\"summary\", remove_words=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_good.create_wordcloud(text=\"summary\", remove_words=[\"\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_app_review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
